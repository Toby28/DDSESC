{"cells":[{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1248,"status":"ok","timestamp":1738696545591,"user":{"displayName":"Chaohao Lin","userId":"02535404984035233613"},"user_tz":300},"id":"-fSKpEeiwlRi","outputId":"8e253530-f5b1-4c0a-b317-20d43373be5e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1715270407819,"user":{"displayName":"Chaohao Lin","userId":"02535404984035233613"},"user_tz":240},"id":"ENa9rJq-FT43","outputId":"9f63d3d5-a944-499c-a91b-adade9fa43a4"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content'"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["pwd"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d_qE2bGZxaQN"},"outputs":[],"source":["pip install noisereduce"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":522574,"status":"ok","timestamp":1738697071458,"user":{"displayName":"Chaohao Lin","userId":"02535404984035233613"},"user_tz":300},"id":"WV6we7I7dtfr","outputId":"f1e296c7-01a9-4bc8-d693-17ebb6819db2"},"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-4-5c9861f012e3>:21: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  tp=torch.load(tp_input_address,map_location=torch.device('cpu'))\n"]},{"output_type":"stream","name":"stdout","text":["torch.Size([17501, 192])\n","torch.Size([17501, 1])\n"]}],"source":["import os\n","import torch\n","list_dir=['Angry','Neutral','Surprise','Sad','Happy']\n","\n","def get_feature():\n","  flag=0\n","  features=0\n","  labels=0\n","\n","  for i in range(11,21):\n","      #input_address='C:/Users/64659/Downloads/Emotional Speech Dataset (ESD)/ESD/'+str(i)+'/'\n","      # output_address='/content/gdrive/MyDrive/paper4_dataset/ESD_devector/'+str(i)+'/'\n","      output_address='/content/gdrive/MyDrive/paper4_dataset/ESD_ecapa/'+str(i)+'/'\n","      for j in list_dir:\n","          output_dir_tp=output_address + j +'/'\n","\n","          for file in os.listdir(output_dir_tp):\n","            #if num>10: break\n","            tp_input_address=output_dir_tp + file\n","\n","            tp=torch.load(tp_input_address,map_location=torch.device('cpu'))\n","            tp=tp.unsqueeze(0)\n","\n","            tp2 = torch.tensor([int(i-11)], dtype=torch.int64)\n","            tp2=tp2.unsqueeze(0)\n","            #print(tp.shape)\n","            #print(tp2.shape)\n","\n","            if flag==0:\n","              flag=1\n","              features=tp\n","              labels=tp2\n","            else:\n","                features=torch.cat((features,tp), axis=0)\n","                labels=torch.cat((labels,tp2), axis=0)\n","  return features, labels\n","\n","feats,labels=get_feature()\n","print(feats.shape)\n","print(labels.shape)"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"vM9-9QbUT4lL","executionInfo":{"status":"ok","timestamp":1738697199888,"user_tz":300,"elapsed":284,"user":{"displayName":"Chaohao Lin","userId":"02535404984035233613"}}},"outputs":[],"source":["labels=labels\n","data=torch.cat((feats,labels),axis=1)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":153,"status":"ok","timestamp":1716584575146,"user":{"displayName":"Chaohao Lin","userId":"02535404984035233613"},"user_tz":240},"id":"KwriDrq6muTV","outputId":"9a39c3a8-7c8f-44fb-94e6-87d8b745e319"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.float32\n"]}],"source":["print(data.dtype)"]},{"cell_type":"code","execution_count":28,"metadata":{"id":"MOSZUSEk9IJO","executionInfo":{"status":"ok","timestamp":1738698053133,"user_tz":300,"elapsed":247,"user":{"displayName":"Chaohao Lin","userId":"02535404984035233613"}}},"outputs":[],"source":["import torch.nn as nn\n","class Network(nn.Module):\n","    def __init__(self, input_dim=16, output_dim=10, num_domains=2, hidden_dim=384):\n","        super().__init__()\n","        layers = []\n","        layers += [nn.Linear(input_dim, hidden_dim)]\n","        layers += [nn.ReLU()]\n","        for _ in range(2):\n","            layers += [nn.Linear(hidden_dim, hidden_dim)]\n","            layers += [nn.ReLU()]\n","        self.shared = nn.Sequential(*layers)\n","\n","        self.lastlayer = nn.Linear(hidden_dim,output_dim)\n","\n","        '''\n","        self.unshared = nn.ModuleList()\n","        for _ in range(num_domains):\n","            self.unshared += [nn.Sequential(nn.Linear(hidden_dim, hidden_dim),\n","                                            nn.ReLU(),\n","                                            nn.Linear(hidden_dim, hidden_dim),\n","                                            nn.ReLU(),\n","                                            nn.Linear(hidden_dim, hidden_dim),\n","                                            nn.ReLU(),\n","                                            nn.Linear(hidden_dim, style_dim))]\n","        '''\n","    def forward(self, z):\n","        h = self.shared(z)\n","        out = self.lastlayer(h)\n","        return out\n","\n","    def get_feature(self,z):\n","        h=self.shared(z)\n","        return h"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6835,"status":"ok","timestamp":1716582692959,"user":{"displayName":"Chaohao Lin","userId":"02535404984035233613"},"user_tz":240},"id":"c_zTTyk9N5NY","outputId":"bba385f7-3278-4a5f-8bf1-81392fb6925d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting torchinfo\n","  Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n","Installing collected packages: torchinfo\n","Successfully installed torchinfo-1.8.0\n"]}],"source":["pip install torchinfo"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iA-Yra4cRbT0"},"outputs":[],"source":["for param in net.parameters():\n","  param.requires_grad = False"]},{"cell_type":"code","execution_count":29,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":239,"status":"ok","timestamp":1738698056135,"user":{"displayName":"Chaohao Lin","userId":"02535404984035233613"},"user_tz":300},"id":"4uwkN9qUNR3B","outputId":"e40ef4ab-4f8d-4d4c-f00c-a9e808780911"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["Network(\n","  (shared): Sequential(\n","    (0): Linear(in_features=192, out_features=256, bias=True)\n","    (1): ReLU()\n","    (2): Linear(in_features=256, out_features=256, bias=True)\n","    (3): ReLU()\n","    (4): Linear(in_features=256, out_features=256, bias=True)\n","    (5): ReLU()\n","  )\n","  (lastlayer): Linear(in_features=256, out_features=10, bias=True)\n",")"]},"metadata":{},"execution_count":29}],"source":["#from torchinfo import summary\n","\n","net=Network(input_dim=192,\n","            hidden_dim=256)\n","net"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":211},"executionInfo":{"elapsed":265,"status":"error","timestamp":1738697228921,"user":{"displayName":"Chaohao Lin","userId":"02535404984035233613"},"user_tz":300},"id":"mclnU5J0QX7c","outputId":"69156efe-d8b2-4c40-9c9a-f556f3365d4a"},"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'summary' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-1f5334a1e68f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m summary(net,\n\u001b[0m\u001b[1;32m      2\u001b[0m         \u001b[0minput_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mcol_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_size\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"output_size\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"num_params\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"trainable\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mcol_width\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         row_settings=[\"var_names\"])\n","\u001b[0;31mNameError\u001b[0m: name 'summary' is not defined"]}],"source":["summary(net,\n","        input_size=(1,256),\n","        col_names=[\"input_size\",\"output_size\",\"num_params\",\"trainable\"],\n","        col_width=20,\n","        row_settings=[\"var_names\"])"]},{"cell_type":"code","execution_count":32,"metadata":{"id":"p2MlHl5ri65b","executionInfo":{"status":"ok","timestamp":1738698088185,"user_tz":300,"elapsed":2,"user":{"displayName":"Chaohao Lin","userId":"02535404984035233613"}}},"outputs":[],"source":["from torch.utils.data import DataLoader, Subset\n","from sklearn.model_selection import train_test_split\n","\n","TEST_SIZE = 0.1\n","BATCH_SIZE = 32\n","SEED = 42\n","\n","# generate indices: instead of the actual data we pass in integers instead\n","train_indices, test_indices, _, _ = train_test_split(\n","    range(len(data.detach().numpy())),\n","    data.detach().numpy()[:,-1],\n","    stratify=data.detach().numpy()[:,-1],\n","    test_size=TEST_SIZE,\n","    random_state=SEED\n",")\n","\n","# generate subset based on indices\n","train_split = Subset(data, train_indices)\n","test_split = Subset(data, test_indices)\n","\n","# create batches\n","train_dataloader_simple = DataLoader(train_split, batch_size=BATCH_SIZE, shuffle=True)\n","test_dataloader_simple = DataLoader(test_split, batch_size=BATCH_SIZE)"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"IRwnUsBRM8wI","colab":{"base_uri":"https://localhost:8080/","height":211},"executionInfo":{"status":"error","timestamp":1738697239650,"user_tz":300,"elapsed":280,"user":{"displayName":"Chaohao Lin","userId":"02535404984035233613"}},"outputId":"23de5c91-3287-4bd6-ba3a-dcb08d29e1ae"},"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'test_dataset' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-32f34dadfc30>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# generate indices: instead of the actual data we pass in integers instead\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m train_indices, test_indices, _, _ = train_test_split(\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mtest_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mstratify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'test_dataset' is not defined"]}],"source":["from torch.utils.data import DataLoader, Subset\n","from sklearn.model_selection import train_test_split\n","\n","TEST_SIZE = 0.1\n","BATCH_SIZE = 32\n","SEED = 42\n","\n","# generate indices: instead of the actual data we pass in integers instead\n","train_indices, test_indices, _, _ = train_test_split(\n","    range(len(test_dataset)),\n","    test_dataset[:,-1],\n","    stratify=test_dataset[:,-1],\n","    test_size=TEST_SIZE,\n","    random_state=SEED\n",")\n","\n","# generate subset based on indices\n","train_split = Subset(test_dataset, train_indices)\n","test_split = Subset(test_dataset, test_indices)\n","\n","# create batches\n","train_dataloader_simple = DataLoader(train_split, batch_size=BATCH_SIZE, shuffle=True)\n","test_dataloader_simple = DataLoader(test_split, batch_size=BATCH_SIZE)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":284,"status":"ok","timestamp":1738011176986,"user":{"displayName":"Chaohao Lin","userId":"02535404984035233613"},"user_tz":300},"id":"s1d_NZG5xftY","outputId":"2f38e154-a774-4b69-b493-5b0efbb01e2c"},"outputs":[{"output_type":"stream","name":"stdout","text":["[3674, 9505, 121, 1017, 15602, 2673, 2523, 14560, 5084, 16314, 775, 17466, 840, 3530, 2667, 7495, 13872, 16344, 16546, 8249, 14449, 12138, 10318, 12389, 95, 14115, 17231, 13188, 295, 7861, 1482, 6398, 15264, 15980, 769, 9804, 1396, 9630, 14276, 2620, 2720, 17415, 216, 17198, 1451, 492, 6490, 11696, 11724, 16671, 1763, 4813, 7686, 1215, 8260, 64, 418, 7254, 4545, 13813, 7709, 2727, 15657, 15171, 13654, 11701, 5665, 3970, 16633, 3367, 12265, 15117, 9764, 3325, 14885, 2066, 10765, 10753, 7038, 975, 10480, 14362, 16148, 2434, 4441, 13301, 15707, 7524, 13778, 5422, 2102, 7923, 13760, 9188, 6589, 7545, 16796, 9649, 5087, 5209, 9571, 510, 14707, 10343, 4975, 3071, 16976, 1815, 16380, 13029, 2558, 1570, 7670, 9977, 17479, 10662, 8726, 2785, 3105, 6057, 10722, 12952, 5500, 7004, 16929, 2615, 7255, 1437, 15599, 12955, 2227, 13846, 8980, 16585, 8540, 8656, 14440, 14784, 1130, 5056, 5199, 4989, 3857, 15710, 5186, 15831, 401, 791, 5924, 14559, 13133, 17010, 14833, 5325, 856, 15786, 2083, 8834, 15866, 2159, 3717, 17005, 10926, 2638, 14806, 8420, 16972, 12964, 4878, 4804, 9316, 2706, 7583, 2501, 747, 8721, 15408, 9103, 13675, 5114, 7188, 17437, 8167, 16539, 12289, 10148, 16894, 3087, 4517, 5633, 4850, 565, 7820, 3310, 17034, 13490, 9796, 3496, 5200, 16205, 13420, 5385, 2649, 3459, 1056, 13095, 13182, 10457, 6788, 13606, 729, 16019, 14589, 11839, 3853, 5703, 7890, 2587, 8890, 7265, 2037, 878, 2357, 6466, 794, 7800, 4537, 2611, 10792, 14083, 13147, 11418, 8255, 11333, 13879, 9953, 10274, 3682, 11802, 1495, 2980, 9361, 4022, 686, 8166, 15447, 5216, 6023, 6506, 871, 16732, 3016, 4646, 6725, 15345, 2279, 392, 14259, 14052, 2465, 13707, 8805, 16143, 13247, 6228, 15062, 276, 15807, 15553, 15075, 6414, 13533, 12856, 600, 14750, 9547, 2857, 16988, 16882, 11854, 8845, 12274, 4611, 11256, 3439, 13216, 15455, 6000, 13392, 14051, 7905, 7791, 3949, 10506, 8282, 12503, 10049, 4536, 3037, 742, 562, 3734, 15725, 14586, 11040, 17002, 702, 9414, 4225, 12991, 1028, 13584, 189, 2130, 2084, 6028, 10349, 14483, 4046, 269, 11016, 2640, 16398, 5639, 16648, 379, 11963, 4409, 4979, 15826, 11593, 9819, 9106, 13050, 6041, 3189, 1367, 647, 206, 4738, 4123, 3297, 11661, 14135, 10250, 6047, 5399, 9331, 4836, 15558, 6735, 11078, 10213, 7236, 8879, 4624, 10914, 5059, 6463, 12775, 1485, 8007, 8184, 4576, 776, 3144, 385, 1839, 466, 3137, 11972, 4764, 11482, 15237, 12667, 1082, 16217, 17017, 9267, 7434, 1499, 337, 16604, 12295, 17351, 14457, 6379, 16591, 11687, 9780, 3340, 5179, 16011, 15507, 4546, 1369, 16033, 13588, 10277, 15351, 459, 1777, 1771, 15401, 10758, 2658, 9623, 13545, 14524, 3445, 10664, 8281, 17019, 11227, 3457, 10988, 1390, 6279, 4680, 5103, 13073, 12542, 16515, 14180, 4146, 2652, 7953, 12166, 15966, 8882, 10144, 16727, 11087, 13407, 1908, 12820, 14406, 14786, 11755, 13712, 6920, 7281, 9141, 1842, 10211, 5839, 1860, 11387, 2763, 5706, 7634, 14925, 6419, 12133, 10162, 13360, 12089, 2067, 3500, 3129, 13414, 14071, 10936, 397, 5420, 7308, 15458, 15245, 2939, 6253, 9457, 10180, 11123, 11683, 1413, 15781, 5906, 14488, 1943, 12171, 3002, 1123, 9445, 16514, 5090, 14855, 2499, 17257, 20, 13942, 12406, 11504, 4650, 2636, 10091, 8385, 2010, 4701, 6947, 4711, 5820, 13790, 6666, 6467, 11994, 8769, 4317, 10106, 3927, 9866, 13531, 15766, 6978, 8174, 9501, 14439, 13735, 9604, 5775, 14027, 14546, 7401, 3756, 4346, 4275, 13523, 7737, 8979, 4280, 1871, 1332, 3091, 15336, 1508, 4756, 13885, 5668, 12185, 957, 6090, 15051, 15499, 1879, 9384, 5239, 2504, 12445, 10589, 7179, 9540, 3907, 2124, 11582, 5869, 13501, 7844, 10583, 9909, 17058, 9965, 16743, 7970, 15448, 13, 15143, 16003, 12639, 6107, 12034, 15616, 378, 11546, 2042, 13012, 16817, 10725, 2194, 6760, 12177, 161, 8209, 7576, 9151, 2616, 11385, 10694, 8972, 7588, 2819, 9352, 16862, 6655, 11195, 13242, 1638, 9375, 5486, 187, 16159, 8771, 10736, 6007, 3074, 3659, 14, 16142, 10643, 16807, 9918, 11041, 5262, 12732, 9643, 7759, 9206, 12769, 17349, 12085, 14436, 10293, 200, 16916, 6136, 12010, 14446, 15543, 1720, 15759, 13110, 12922, 4318, 4677, 12001, 10832, 8111, 5604, 7899, 2000, 12740, 4535, 13672, 5395, 8941, 16760, 1238, 3335, 3697, 1337, 2341, 16596, 9552, 16429, 8063, 12344, 9765, 12869, 4435, 252, 13035, 8867, 7985, 3125, 1020, 7824, 17324, 11785, 10844, 14596, 6557, 3661, 13439, 1836, 5696, 2177, 14984, 7460, 7755, 15542, 5518, 12600, 7067, 4728, 3191, 16659, 7790, 7914, 10603, 2422, 4553, 6485, 12099, 12543, 14078, 8362, 12108, 4388, 1064, 14134, 10712, 17138, 13869, 5656, 4293, 1770, 12337, 8510, 16197, 3544, 4619, 12346, 16484, 11498, 11194, 11720, 3522, 15698, 13882, 16350, 6012, 8405, 8742, 9594, 16057, 15618, 17001, 8730, 5848, 7981, 8624, 3640, 3636, 8016, 6512, 10984, 15300, 8981, 1892, 10464, 13926, 8298, 13930, 9662, 12163, 7971, 1972, 15480, 5352, 6034, 1459, 5058, 11888, 8008, 17425, 15214, 14908, 6333, 8432, 17309, 4588, 16395, 11600, 15795, 2056, 9437, 10253, 4349, 13514, 719, 9936, 12327, 16195, 6718, 14940, 10472, 1522, 2644, 3913, 1784, 166, 1901, 10447, 5215, 17353, 17151, 1044, 7615, 12247, 5208, 13286, 16008, 4111, 17373, 11097, 8241, 9370, 9277, 2281, 6278, 17108, 17295, 5745, 2918, 12679, 9406, 16420, 6590, 13962, 17313, 1154, 15682, 4969, 5089, 11876, 12370, 5450, 1991, 7228, 4405, 1411, 4078, 10133, 13720, 8065, 7420, 5088, 10892, 40, 9323, 2705, 2622, 16476, 13452, 9353, 7342, 5321, 766, 1773, 455, 3610, 5235, 8333, 4550, 10594, 13538, 4403, 10011, 3019, 16559, 5620, 2543, 4964, 4597, 14103, 6131, 16541, 11490, 16293, 9112, 10757, 343, 10065, 13737, 1184, 1577, 16481, 14890, 12994, 15050, 14947, 11723, 9033, 12760, 8143, 1687, 7328, 3687, 7209, 6020, 9003, 4159, 17205, 11267, 14197, 15253, 3472, 12995, 3023, 1267, 1275, 11975, 7621, 16771, 13305, 6075, 1606, 6152, 11060, 2386, 16605, 7139, 7231, 11579, 6225, 3793, 8609, 5873, 5630, 12270, 2689, 11576, 13295, 2061, 5153, 15489, 11670, 10622, 7025, 7024, 9171, 134, 2384, 7335, 9383, 9859, 15365, 15207, 15550, 1685, 2481, 10428, 6610, 16012, 13815, 16459, 7956, 13748, 14626, 10105, 9559, 2663, 5832, 230, 8201, 9768, 15858, 6803, 5371, 6437, 3693, 1980, 15844, 10062, 6369, 6060, 3010, 4994, 8796, 4490, 10420, 5819, 563, 13015, 5362, 1841, 8975, 7881, 15217, 10022, 3911, 11550, 14373, 10008, 5647, 15169, 15461, 474, 11811, 3155, 16044, 7138, 13579, 16993, 15406, 16082, 6600, 17177, 7667, 11239, 6208, 13955, 8321, 9981, 5007, 10653, 11246, 10473, 7010, 16078, 9759, 11552, 508, 2743, 6265, 7593, 11221, 13781, 10816, 1294, 15178, 1705, 15899, 16852, 6129, 8865, 12802, 13798, 5275, 2044, 5982, 14754, 2846, 12887, 15788, 9145, 12081, 15097, 12104, 15251, 87, 2264, 2338, 7111, 5394, 5225, 995, 5268, 14823, 10352, 5981, 15897, 7842, 3293, 8915, 241, 484, 7484, 15384, 13313, 6366, 12154, 3078, 8274, 14513, 6235, 15999, 10568, 14055, 10767, 1264, 1648, 12480, 6560, 5615, 3759, 7015, 15738, 1051, 5408, 12552, 14179, 17427, 7928, 15255, 10474, 16942, 11321, 11978, 12611, 7942, 16626, 16487, 14805, 6885, 10759, 9724, 1865, 12003, 564, 4232, 11540, 9086, 2900, 10876, 2153, 955, 8353, 14022, 9493, 14815, 863, 2444, 10135, 12897, 10791, 13240, 10588, 15520, 12333, 13453, 8036, 3275, 15331, 4582, 8553, 11896, 9954, 6777, 8211, 3874, 8989, 14378, 3889, 8244, 1162, 8271, 15424, 9593, 5436, 8203, 12135, 16704, 960, 14045, 10668, 2890, 15200, 1746, 12770, 12795, 4944, 11680, 805, 12262, 13665, 9366, 4926, 7415, 6898, 8970, 11334, 2685, 8973, 12936, 17250, 12689, 14753, 13615, 8041, 8227, 17401, 16183, 12780, 1076, 2554, 5233, 7529, 683, 34, 8639, 16068, 5963, 5712, 13234, 11281, 13633, 10841, 7543, 14819, 14463, 12729, 4076, 6338, 10838, 16112, 13751, 13558, 11936, 14860, 1702, 17003, 12837, 9853, 7218, 725, 6401, 11752, 5912, 1724, 14721, 10980, 12592, 16022, 7176, 12129, 16480, 1758, 7282, 3836, 12846, 16853, 5011, 7069, 13527, 3582, 3485, 6049, 13894, 14557, 10540, 15941, 14755, 2265, 8718, 6764, 3900, 14877, 7697, 14727, 4754, 4533, 1515, 15398, 8828, 1095, 10972, 7740, 4132, 15634, 16614, 4598, 16065, 1016, 11049, 1513, 5857, 15965, 1528, 4815, 5599, 4606, 11327, 2463, 6909, 12015, 11172, 12620, 12011, 2058, 14035, 1086, 10201, 8236, 17024, 10566, 7299, 11784, 4147, 3222, 11388, 7996, 6661, 16729, 15195, 13835, 4473, 12910, 13376, 3163, 4412, 11741, 21, 5612, 10323, 14538, 6470, 14363, 14767, 11737, 11399, 7873, 815, 9143, 13079, 6503, 14077, 17060, 13507, 15942, 14955, 7731, 16664, 6830, 14200, 9134, 17114, 12045, 16130, 1584, 16925, 12583, 8378, 6997, 10476, 5805, 3404, 2660, 8437, 9413, 4450, 6883, 17344, 13499, 3794, 11694, 11052, 1484, 1038, 6805, 14038, 9529, 2132, 12252, 17090, 16242, 9125, 12382, 13025, 15038, 13969, 4511, 646, 7193, 1478, 13553, 16073, 5237, 11532, 6697, 11731, 6586, 5091, 10322, 8728, 2876, 8131, 8611, 4428, 5072, 8848, 17369, 14024, 4202, 9347, 2936, 11106, 891, 6323, 779, 8433, 130, 16860, 2327, 12220, 4131, 7832, 3824, 8959, 1071, 9252, 10072, 7087, 5180, 16579, 502, 6251, 6807, 11988, 2337, 14494, 7989, 8985, 15918, 11943, 16509, 13662, 16150, 4866, 8187, 11126, 4881, 8278, 16893, 17303, 9876, 13089, 15683, 7454, 11121, 14040, 12569, 5678, 1585, 5190, 1855, 14854, 9892, 10407, 763, 15578, 14294, 7662, 15827, 11411, 11219, 7897, 1849, 9334, 15041, 11319, 3083, 14367, 13387, 870, 12531, 12148, 14911, 15524, 1021, 6084, 10532, 9913, 14818, 5474, 3552, 17026, 3676, 10043, 8273, 2169, 13456, 1152, 11268, 6277, 11654, 13310, 1756, 11445, 8811, 15606, 9164, 13145, 15958, 8192, 4190, 4041, 15120, 4783, 9588, 9882, 5681, 12485, 14927, 929, 7711, 3285, 1751, 11538, 5664, 6522, 16529, 6231, 14064, 10152, 2681, 16121, 10188, 6902, 12488, 7288, 5907, 6543, 10546, 4589, 1180, 12807, 15206, 8302, 7476, 2754, 10217, 9212, 5412, 5293, 4043, 14046, 5051, 897, 860, 4301, 5975, 14094, 7935, 3041, 16505, 3433, 520, 13011, 9094, 1126, 4907, 288, 15798, 3452, 12903, 6721, 11456, 13446, 15128, 2550, 2253, 14534, 15031, 7253, 12101, 7435, 6008, 16260, 2859, 10858, 391, 6222, 15865, 3236, 17352, 3524, 3708, 10154, 7351, 4903, 5096, 12755, 7109, 10281, 4439, 10026, 13043, 14453, 6994, 1363, 1297, 5702, 15834, 14848, 4974, 3490, 15690, 8020, 4627, 91, 6168, 13104, 15484, 3132, 12824, 16726, 612, 4167, 9825, 15304, 11186, 1025, 7056, 205, 3821, 5174, 11730, 13804, 9389, 1104, 4007, 11891, 15121, 2411, 5672, 3820, 7654, 9726, 10200, 4788, 15003, 5821, 9754, 9608, 4410, 15656, 1129, 7089, 14689, 6058, 9610, 7356, 6731, 7782, 8586, 8466, 6674, 1974, 1935, 10155, 1579, 2696, 9592, 17392, 642, 10709, 6475, 3143, 10985, 2302, 12993, 2298, 17448, 11792, 7638, 3402, 592, 6564, 15466, 17246, 5625, 8565, 2623, 17225, 7919, 12204, 6003, 7595, 5904, 13473, 3612, 315, 699, 10829, 17070, 8640, 13841, 6125, 12817, 8482, 11002, 4997, 804, 5255, 12519, 2832, 13833, 16301, 17438, 14693, 12978, 9725, 9417, 16674, 6963, 11349, 8205, 11604, 2208, 5824, 6782, 15485, 12712, 15880, 13319, 15750, 8931, 6672, 10304, 14763, 14985, 17442, 6098, 7365, 201, 3936, 16940, 10165, 4651, 9398, 2275, 5107, 3930, 7575, 2586, 12353, 5959, 1590, 12625, 3453, 12805, 16712, 7352, 10996, 5743, 1957, 5415, 17162, 330, 8839, 15405, 11156, 8982, 6799, 3683, 6211, 1241, 15548, 387, 7257, 2920, 14468, 6518, 4372, 5537, 12850, 831, 98, 12362, 1500, 11648, 17115, 10538, 12793, 406, 9887, 1597, 14787, 3700, 10087, 10642]\n","[175. 175. 175. 175. 175. 175. 175. 175. 175. 175.]\n"]}],"source":["import numpy as np\n","print(test_split.indices)\n","cal=np.zeros((10))\n","\n","for i in test_split.indices:\n","  #print(i)\n","  #print(int(test_split.dataset[i,-1]))\n","  cal[int(test_split.dataset[i,-1])]+=1\n","\n","print(cal)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":463,"status":"ok","timestamp":1716582574746,"user":{"displayName":"Chaohao Lin","userId":"02535404984035233613"},"user_tz":240},"id":"WOjnxPvKR5wK","outputId":"cd15c236-58d6-4c4f-ae06-73a59c72ba96"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([1, 257])\n"]}],"source":["flag=0\n","tx=0\n","for i in test_split.indices:\n","  if flag==0:\n","    flag=1\n","    tx=test_split.dataset[i,:].unsqueeze(0)\n","    print(tx.shape)\n","  else:\n","      tx=torch.cat((tx,test_split.dataset[i,:].unsqueeze(0)), axis=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S6g-qmQnTDRA"},"outputs":[],"source":["torch.save(tx, \"ESDresnet_baseline_seen1750.pt\")"]},{"cell_type":"code","execution_count":33,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":211},"executionInfo":{"elapsed":250,"status":"error","timestamp":1738698092198,"user":{"displayName":"Chaohao Lin","userId":"02535404984035233613"},"user_tz":300},"id":"dm7WNYBmA0p4","outputId":"b22c21df-e0ee-4f8a-fdad-8b84e8e70eca"},"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'train_data_simple' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-33-5ba99e8a2e38>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m train_dataloader_simple = DataLoader(dataset=train_data_simple,\n\u001b[0m\u001b[1;32m      2\u001b[0m                                      \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                                      \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                      num_workers=NUM_WORKERS)\n\u001b[1;32m      5\u001b[0m test_dataloader_simple = DataLoader(dataset=test_data_simple,\n","\u001b[0;31mNameError\u001b[0m: name 'train_data_simple' is not defined"]}],"source":["train_dataloader_simple = DataLoader(dataset=train_data_simple,\n","                                     batch_size=BATCH_SIZE,\n","                                     shuffle=True,\n","                                     num_workers=NUM_WORKERS)\n","test_dataloader_simple = DataLoader(dataset=test_data_simple,\n","                                    batch_size=BATCH_SIZE,\n","                                    shuffle=False,\n","                                    num_workers=NUM_WORKERS)"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"oMPVh0TdA5-I","executionInfo":{"status":"ok","timestamp":1738697299041,"user_tz":300,"elapsed":258,"user":{"displayName":"Chaohao Lin","userId":"02535404984035233613"}}},"outputs":[],"source":["\n","# Get a single image batch\n","image_batch = next(iter(train_dataloader_simple))\n","image_batch.shape\n","device=torch.device('cpu')"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"7UrFv5QWA9Ts","executionInfo":{"status":"ok","timestamp":1738697301998,"user_tz":300,"elapsed":293,"user":{"displayName":"Chaohao Lin","userId":"02535404984035233613"}}},"outputs":[],"source":["# Create train_step()\n","def train_step(model: torch.nn.Module,\n","               dataloader: torch.utils.data.DataLoader,\n","               loss_fn: torch.nn.Module,\n","               optimizer:torch.optim.Optimizer,\n","               device=device):\n","  # Put the model in train mode\n","  model.train()\n","\n","  # Setup train loss and train accuracy values\n","  train_loss, train_acc = 0, 0\n","\n","  # Loop through data loader data batches\n","  for batch, tp in enumerate(dataloader):\n","    # Send data to the target device\n","    X=tp[:,:-1]\n","\n","    y=tp[:,-1]\n","    #y=y.type(torch.LongTensor)\n","    X, y = X.to(device), y.to(device)\n","\n","    # 1. Forward pass\n","    y_pred = model(X) # output model logits\n","    #y_pred = torch.softmax(y_pred,dim=1)\n","    #print(y_pred,y)\n","    # 2. Calculate the loss\n","    y_pred=y_pred.type(torch.float32)\n","    loss = loss_fn(y_pred, y.long())\n","    train_loss += loss.item()\n","\n","    # 3. Optimizer zero grad\n","    optimizer.zero_grad()\n","\n","    # 4. Loss backward\n","    loss.backward()\n","\n","    # 5. Optimizer step\n","    optimizer.step()\n","\n","    # Calculate accuracy metric\n","    y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)\n","    train_acc += (y_pred_class==y).sum().item()/len(y_pred)\n","\n","  # Adjust metrics to get average loss and accuracy per batch\n","  train_loss = train_loss / len(dataloader)\n","  train_acc = train_acc / len(dataloader)\n","  return train_loss, train_acc"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"BZ6So4I0A_X3","executionInfo":{"status":"ok","timestamp":1738697307262,"user_tz":300,"elapsed":293,"user":{"displayName":"Chaohao Lin","userId":"02535404984035233613"}}},"outputs":[],"source":["# Create a test step\n","def test_step(model: torch.nn.Module,\n","              dataloader: torch.utils.data.DataLoader,\n","              loss_fn: torch.nn.Module,\n","              device=device):\n","  # Put model in eval mode\n","  model.eval()\n","\n","  # Setup test loss and test accuracy values\n","  test_loss, test_acc = 0,  0\n","\n","  # Turn on inference mode\n","  with torch.inference_mode():\n","    # Loop through DataLoader batches\n","    for batch, tp in enumerate(dataloader):\n","      # Send data to the target device\n","      X=tp[:,:-1]\n","      y=tp[:,-1]\n","      X, y = X.to(device), y.to(device)\n","\n","      # 1. Forward pass\n","      test_pred_logits = model(X)\n","      test_pred_logits=test_pred_logits.type(torch.float32)\n","      # 2. Calculate the loss\n","      loss = loss_fn(test_pred_logits, y.long())\n","      test_loss += loss.item()\n","\n","      # Calculate the accuracy\n","      test_pred_labels = test_pred_logits.argmax(dim=1)\n","      test_acc += ((test_pred_labels == y).sum().item()/len(test_pred_labels))\n","\n","  # Adjust metrics to get average loss and accuracy per batch\n","  test_loss = test_loss / len(dataloader)\n","  test_acc = test_acc / len(dataloader)\n","  return test_loss, test_acc\n"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"8Fcq0uGmBDXc","executionInfo":{"status":"ok","timestamp":1738697310215,"user_tz":300,"elapsed":228,"user":{"displayName":"Chaohao Lin","userId":"02535404984035233613"}}},"outputs":[],"source":["\n","from tqdm.auto import tqdm\n","\n","# 1. Create a train function that takes in various model parameters + optimizer + dataloaders + loss function\n","def train(model: torch.nn.Module,\n","          train_dataloader,\n","          test_dataloader,\n","          optimizer,\n","          loss_fn: torch.nn.Module = nn.CrossEntropyLoss(),\n","          epochs: int = 5,\n","          device=device):\n","\n","  # 2. Create empty results dictionary\n","  results = {\"train_loss\": [],\n","             \"train_acc\": [],\n","             \"test_loss\": [],\n","             \"test_acc\": []}\n","\n","  # 3. Loop through training and testing steps for a number of epochs\n","  for epoch in tqdm(range(epochs)):\n","    train_loss, train_acc = train_step(model=model,\n","                                       dataloader=train_dataloader,\n","                                       loss_fn=loss_fn,\n","                                       optimizer=optimizer,\n","                                       device=device)\n","    test_loss, test_acc = test_step(model=model,\n","                                    dataloader=test_dataloader,\n","                                    loss_fn=loss_fn,\n","                                    device=device)\n","\n","    # 4. Print out what's happening\n","    print(f\"Epoch: {epoch} | Train loss: {train_loss:.4f} | Train acc: {train_acc:.4f} | Test loss: {test_loss:.4f} | Test acc: {test_acc:.4f}\")\n","\n","    # 5. Update results dictionary\n","    results[\"train_loss\"].append(train_loss)\n","    results[\"train_acc\"].append(train_acc)\n","    results[\"test_loss\"].append(test_loss)\n","    results[\"test_acc\"].append(test_acc)\n","\n","  # 6. Return the filled results at the end of the epochs\n","  return results"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":596,"referenced_widgets":["f6e54051c5e7456fae85a41652a61ff5","42d8d50db21747808f0514b28c40bb3b","22b7ec64d2ac4975aac0a0d0edac2281","567a33e934af4a2ca97082904dfce9b6","fa89217af99a4791881046dba732b95a","8a29f836f7814933a344b3b3c85ce9c9","c98ce58529e5430e92d6c2cfa6a1946d","ab6096108d9e45b7a1ff3531e5ee2b65","28417682f3d8421596229acbd39c73f6","e110b623844e44a6beab52785b173877","ea52840e5f124eeb9d38b1dc7f94e94b"]},"id":"WikD0MUNBG20","executionInfo":{"status":"error","timestamp":1738697390889,"user_tz":300,"elapsed":14757,"user":{"displayName":"Chaohao Lin","userId":"02535404984035233613"}},"outputId":"bc360217-3492-49a5-9661-dfa84f17a6e5"},"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/400 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f6e54051c5e7456fae85a41652a61ff5"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch: 0 | Train loss: 0.1178 | Train acc: 0.9771 | Test loss: 0.0080 | Test acc: 0.9977\n","Epoch: 1 | Train loss: 0.0022 | Train acc: 0.9997 | Test loss: 0.0054 | Test acc: 0.9989\n","Epoch: 2 | Train loss: 0.0005 | Train acc: 1.0000 | Test loss: 0.0057 | Test acc: 0.9989\n","Epoch: 3 | Train loss: 0.0003 | Train acc: 1.0000 | Test loss: 0.0048 | Test acc: 0.9989\n","Epoch: 4 | Train loss: 0.0001 | Train acc: 1.0000 | Test loss: 0.0051 | Test acc: 0.9989\n","Epoch: 5 | Train loss: 0.0001 | Train acc: 1.0000 | Test loss: 0.0046 | Test acc: 0.9989\n","Epoch: 6 | Train loss: 0.0001 | Train acc: 1.0000 | Test loss: 0.0047 | Test acc: 0.9989\n","Epoch: 7 | Train loss: 0.0000 | Train acc: 1.0000 | Test loss: 0.0049 | Test acc: 0.9989\n","Epoch: 8 | Train loss: 0.0000 | Train acc: 1.0000 | Test loss: 0.0047 | Test acc: 0.9989\n","Epoch: 9 | Train loss: 0.0000 | Train acc: 1.0000 | Test loss: 0.0048 | Test acc: 0.9989\n","Epoch: 10 | Train loss: 0.0000 | Train acc: 1.0000 | Test loss: 0.0046 | Test acc: 0.9994\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-19-cadd2e38d3fd>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# Train model_0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m model_0_results = train(model=model_0,\n\u001b[0m\u001b[1;32m     26\u001b[0m                         \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_dataloader_simple\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                         \u001b[0mtest_dataloader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_dataloader_simple\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-16-8a18561117fb>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_dataloader, test_dataloader, optimizer, loss_fn, epochs, device)\u001b[0m\n\u001b[1;32m     18\u001b[0m   \u001b[0;31m# 3. Loop through training and testing steps for a number of epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     train_loss, train_acc = train_step(model=model,\n\u001b[0m\u001b[1;32m     21\u001b[0m                                        \u001b[0mdataloader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                                        \u001b[0mloss_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-14-54b2f611a3c6>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(model, dataloader, loss_fn, optimizer, device)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;31m# 4. Loss backward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;31m# 5. Optimizer step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             )\n\u001b[0;32m--> 581\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m     \u001b[0mgrad_tensors_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tensor_or_tensors_to_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m     \u001b[0mgrad_tensors_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_grads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_grads_batched\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mretain_graph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36m_make_grads\u001b[0;34m(outputs, grads, is_grads_batched)\u001b[0m\n\u001b[1;32m    218\u001b[0m                     \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                     new_grads.append(\n\u001b[0;32m--> 220\u001b[0;31m                         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreserve_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m                     )\n\u001b[1;32m    222\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["\n","# Set random seeds\n","torch.manual_seed(42)\n","torch.cuda.manual_seed(42)\n","\n","# Set number of epochs\n","NUM_EPOCHS = 400\n","\n","# Recreate an instance of TinyVGG\n","'''\n","model_0 = TinyVGG(input_shape=3, # number of color channels of our target images\n","                  hidden_units=10,\n","                  output_shape=len(train_data.classes)).to(device)\n","'''\n","model_0=net\n","# Setup loss function and optimizer\n","loss_fn = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(params=model_0.parameters(),\n","                             lr=0.0001)\n","\n","# Start the timer\n","from timeit import default_timer as timer\n","start_time = timer()\n","\n","# Train model_0\n","model_0_results = train(model=model_0,\n","                        train_dataloader=train_dataloader_simple,\n","                        test_dataloader=test_dataloader_simple,\n","                        optimizer=optimizer,\n","                        loss_fn=loss_fn,\n","                        epochs=NUM_EPOCHS)\n","\n","# End the timer and print out how long it took\n","end_time = timer()\n","print(f\"Total training time: {end_time-start_time:.3f} seconds\")\n"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"ag_rLBoqmWbT","executionInfo":{"status":"ok","timestamp":1738697400961,"user_tz":300,"elapsed":274,"user":{"displayName":"Chaohao Lin","userId":"02535404984035233613"}}},"outputs":[],"source":["# Create a test step\n","\n","model_0.eval()\n","\n","# Setup test loss and test accuracy values\n","test_loss, test_acc = 0,  0\n","flag=0\n","# Turn on inference mode\n","with torch.inference_mode():\n","  # Loop through DataLoader batches\n","  for batch, tp in enumerate(test_dataloader_simple):\n","    # Send data to the target device\n","    X=tp[:,:-1]\n","    y=tp[:,-1]\n","    X, y = X.to(device), y.to(device)\n","\n","    # 1. Forward pass\n","    test_pred_logits = model_0.get_feature(X)\n","    test_pred_logits=test_pred_logits.type(torch.float32)\n","    #print(test_pred_logits)\n","    if flag==0:\n","      txxx=test_pred_logits\n","      yxxx=y\n","      flag=1\n","    else:\n","      txxx=torch.cat((txxx,test_pred_logits))\n","      yxxx=torch.cat((yxxx,y))\n","\n","yxxx=yxxx.unsqueeze(-1)\n","output=torch.cat((txxx,yxxx),dim=1)\n","\n","\n","\n","# Adjust metrics to get average loss and accuracy per batch\n"]},{"cell_type":"code","execution_count":37,"metadata":{"id":"13h16eIvWUp9","executionInfo":{"status":"ok","timestamp":1738699821824,"user_tz":300,"elapsed":290,"user":{"displayName":"Chaohao Lin","userId":"02535404984035233613"}}},"outputs":[],"source":["# for unseen dataset\n","\n","model_0.eval()\n","\n","# Setup test loss and test accuracy values\n","test_loss, test_acc = 0,  0\n","flag=0\n","# Turn on inference mode\n","with torch.inference_mode():\n","  # Loop through DataLoader batches\n","  for batch, tp in enumerate(test_dataloader2):\n","    # Send data to the target device\n","    X=tp[:,:-1]\n","    y=tp[:,-1]\n","    X, y = X.to(device), y.to(device)\n","    X=X.type(torch.float32)\n","    # 1. Forward pass\n","    test_pred_logits = model_0.get_feature(X)\n","    test_pred_logits=test_pred_logits.type(torch.float32)\n","    #print(test_pred_logits)\n","    if flag==0:\n","      txxx=test_pred_logits\n","      yxxx=y\n","      flag=1\n","    else:\n","      txxx=torch.cat((txxx,test_pred_logits))\n","      yxxx=torch.cat((yxxx,y))\n","\n","yxxx=yxxx.unsqueeze(-1)\n","output=torch.cat((txxx,yxxx),dim=1)"]},{"cell_type":"code","execution_count":38,"metadata":{"id":"EGgHPzsWrv-6","executionInfo":{"status":"ok","timestamp":1738699853189,"user_tz":300,"elapsed":251,"user":{"displayName":"Chaohao Lin","userId":"02535404984035233613"}}},"outputs":[],"source":["torch.save(output, \"IEMCAPcapa_ft.pt\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":148,"status":"ok","timestamp":1716583137758,"user":{"displayName":"Chaohao Lin","userId":"02535404984035233613"},"user_tz":240},"id":"q_1jTsUoQd7I","outputId":"4d1cc746-a55f-4236-b4a7-d0b5c1ebf87f"},"outputs":[{"name":"stdout","output_type":"stream","text":["[INFO] Saving model to: ESDrvectorFTmodel.pth\n"]}],"source":["#%%writefile going_modular/utils.py\n","\"\"\"\n","File containing various utility functions for PyTorch model training.\n","\"\"\"\n","import torch\n","\n","from pathlib import Path\n","\n","def save_model(model: torch.nn.Module,\n","               target_dir: str,\n","               model_name: str):\n","  \"\"\"Saves a PyTorch model to a target directory.\n","\n","  Args:\n","    model: A target PyTorch model to save.\n","    target_dir: A directory for saving the model to.\n","    model_name: A filename for the saved model. Should include\n","      either \".pth\" or \".pt\" as the file extension.\n","\n","  Example usage:\n","    save_model(model=model_0,\n","               target_dir=\"models\",\n","               model_name=\"05_going_modular_tingvgg_model.pth\")\n","  \"\"\"\n","  # Create target directory\n","  target_dir_path = Path(target_dir)\n","  target_dir_path.mkdir(parents=True,\n","                        exist_ok=True)\n","\n","  # Create model save path\n","  assert model_name.endswith(\".pth\") or model_name.endswith(\".pt\"), \"model_name should end with '.pt' or '.pth'\"\n","  model_save_path = target_dir_path / model_name\n","\n","  # Save the model state_dict()\n","  print(f\"[INFO] Saving model to: {model_save_path}\")\n","  torch.save(obj=model.state_dict(),\n","             f=model_save_path)\n","\n","save_model(model_0,\"./\",\"ESDrvectorFTmodel.pth\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1716583153575,"user":{"displayName":"Chaohao Lin","userId":"02535404984035233613"},"user_tz":240},"id":"9gBpzcnHRHdl","outputId":"ec318786-5d3c-478d-fc01-f0e31e9e4dfc"},"outputs":[{"data":{"text/plain":["<All keys matched successfully>"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["# To load in a saved state_dict we have to instantiate a new instance of our model class\n","loaded_model_0 = net\n","\n","# Load the saved state_dict of model_0 (this will update the new instance with updated parameters)\n","loaded_model_0.load_state_dict(torch.load(f=\"ESDrvectorFTmodel.pth\"))"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":267,"status":"ok","timestamp":1738698016628,"user":{"displayName":"Chaohao Lin","userId":"02535404984035233613"},"user_tz":300},"id":"tXKWu-FVVR3F","outputId":"cfc5718a-7bde-493d-f5b8-1363c0e4a39a"},"outputs":[{"output_type":"stream","name":"stdout","text":["(384,)\n","(360,)\n","(319,)\n","(257,)\n","(381,)\n","(1701,)\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-26-7ca20c2bb531>:12: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  x1=torch.load('iemepaca_sess' + str(i) +'_neu1.pt',map_location=torch.device('cpu'))\n"]}],"source":["import torch\n","import numpy as np\n","\n","\n","tp1=0\n","tp2=0\n","for i in range(1,6):\n","\n","  # x1=torch.load('iemdvector_sess' + str(i) +'_neu1.pt',map_location=torch.device('cpu'))\n","  # x2=np.loadtxt('iemdvector_sess' + str(i) +'_neu1.npy')+2*(i-1)\n","\n","  x1=torch.load('iemepaca_sess' + str(i) +'_neu1.pt',map_location=torch.device('cpu'))\n","  x2=np.loadtxt('iemepaca_sess' + str(i) +'_neu1.npy')+2*(i-1)\n","  print(x2.shape)\n","  if i==1:\n","    tp1=x1.detach().numpy()\n","    tp2=x2\n","  else:\n","    tp1=np.concatenate((tp1,x1.detach().numpy()), axis=0)\n","    tp2=np.concatenate((tp2,x2), axis=0)\n","\n","print(tp2.shape)"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":232,"status":"ok","timestamp":1738698028037,"user":{"displayName":"Chaohao Lin","userId":"02535404984035233613"},"user_tz":300},"id":"bWSAFYCPVSF4","outputId":"ba4b6689-af21-4c57-9f49-e7463d10f5e3"},"outputs":[{"output_type":"stream","name":"stdout","text":["(3974,)\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-27-fa9a1699e49d>:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  x1=torch.load('iemecapa_sess' + str(i) +'_' + j + '.pt',map_location=torch.device('cpu'))\n"]}],"source":["lis=['ang2','hap','sad','sur']\n","for j in lis:\n","  for i in range(1,6):\n","\n","    x1=torch.load('iemecapa_sess' + str(i) +'_' + j + '.pt',map_location=torch.device('cpu'))\n","    x2=np.loadtxt('iemecapa_sess' + str(i) +'_' + j + '.npy')+2*(i-1)\n","    tp1=np.concatenate((tp1,x1.detach().numpy()), axis=0)\n","    tp2=np.concatenate((tp2,x2), axis=0)\n","print(tp2.shape)"]},{"cell_type":"code","execution_count":35,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":272,"status":"ok","timestamp":1738698161138,"user":{"displayName":"Chaohao Lin","userId":"02535404984035233613"},"user_tz":300},"id":"WSxnLlCAWjRI","outputId":"b7dae8f4-6375-4d3b-cb41-5ffe679cd47a"},"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-35-66d54948cc62>:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  tp22=torch.tensor(tp22,dtype=torch.float32)\n"]}],"source":["tp11=torch.tensor(tp1,dtype=torch.float32)\n","\n","tp22=torch.from_numpy(tp2)\n","tp22=torch.tensor(tp22,dtype=torch.float32)\n","\n","test_dataset=torch.cat((tp11,tp22.unsqueeze(-1)), axis=1)"]},{"cell_type":"code","execution_count":36,"metadata":{"executionInfo":{"elapsed":244,"status":"ok","timestamp":1738698167206,"user":{"displayName":"Chaohao Lin","userId":"02535404984035233613"},"user_tz":300},"id":"mWRMZkYGYVYJ"},"outputs":[],"source":["test_dataloader2 = DataLoader(test_dataset, batch_size=BATCH_SIZE)"]},{"cell_type":"markdown","metadata":{"id":"0cs5TyoVQc8p"},"source":[]},{"cell_type":"code","execution_count":22,"metadata":{"id":"ihZl1dX9Zqhw","executionInfo":{"status":"ok","timestamp":1738697641010,"user_tz":300,"elapsed":259,"user":{"displayName":"Chaohao Lin","userId":"02535404984035233613"}}},"outputs":[],"source":["import torch.nn as nn\n","class Network_main(nn.Module):\n","    def __init__(self, input_dim=16, output_dim=64, num_domains=2, hidden_dim=384):\n","        super().__init__()\n","        layers = []\n","        layers += [nn.Linear(input_dim, hidden_dim)]\n","        layers += [nn.ReLU()]\n","        for _ in range(2):\n","            layers += [nn.Linear(hidden_dim, hidden_dim)]\n","            layers += [nn.ReLU()]\n","        self.shared = nn.Sequential(*layers)\n","\n","        self.speakerencoder=nn.ModuleList()\n","        self.speakerencoder += [nn.Sequential(nn.Linear(hidden_dim, hidden_dim),\n","                                            nn.ReLU(),\n","                                            nn.Linear(hidden_dim, hidden_dim),\n","                                            nn.LayerNorm(),\n","                                            nn.Linear(hidden_dim, self.out_channels * 2))]\n","\n","        self.emotionencoder=nn.ModuleList()\n","        self.emotionencoder += [nn.Sequential(nn.Linear(hidden_dim, hidden_dim),\n","                                    nn.ReLU(),\n","                                    nn.Linear(hidden_dim, hidden_dim),\n","                                    nn.LayerNorm(),\n","                                    nn.Linear(hidden_dim, self.out_channels * 2))]\n","        self.decoder=nn.ModuleList()\n","        self.decoder += [nn.Sequential(nn.Linear(hidden_dim, hidden_dim),\n","                                    nn.ReLU(),\n","                                    nn.Linear(hidden_dim, hidden_dim),\n","                                    nn.ReLU(),\n","                                    nn.Linear(hidden_dim, input_dim))]\n","\n","        self.emocls = nn.ModuleList()\n","        self.emocls += [nn.Sequential(nn.Linear(hidden_dim, hidden_dim),\n","                                    nn.ReLU(),\n","                                    nn.Linear(hidden_dim, emoclassnum))]\n","\n","        self.spkcls = nn.ModuleList()\n","        self.spkcls += [nn.Sequential(nn.Linear(hidden_dim, hidden_dim),\n","                                    nn.ReLU(),\n","                                    nn.Linear(hidden_dim, spkclassnum))]\n","\n","\n","\n","        '''\n","        self.unshared = nn.ModuleList()\n","        for _ in range(num_domains):\n","            self.unshared += [nn.Sequential(nn.Linear(hidden_dim, hidden_dim),\n","                                            nn.ReLU(),\n","                                            nn.Linear(hidden_dim, hidden_dim),\n","                                            nn.ReLU(),\n","                                            nn.Linear(hidden_dim, style_dim))]\n","        '''\n","    def forward(self, x):\n","        h=self.shared(x)\n","        emo_mu, emo_log_std = self.emotionencoder(h)\n","        spk_mu, spk_log_std = self.speakerencoder(h)\n","\n","        z_emo = sample(emo_mu, emo_log_std)\n","        z_spk = sample(spk_mu, spk_log_std)\n","\n","        dec_in = torch.cat([z_emo, z_spk], dim=1)\n","        x_hat = self.decoder(dec_in)\n","\n","        dec_in_emo = torch.cat([emo_mu, emo_log_std], dim=1)\n","        emoresult=self.emocls(dec_in_emo)\n","\n","        dec_in_spk = torch.cat([spk_mu, spk_log_std], dim=1)\n","        spkresult=self.spkcls(dec_in_spk)\n","\n","\n","        return {'x_hat': x_hat, 'emo_mu': emo_mu, 'emo_log_std': emo_log_std,'z_emo': z_emo,\n","                 'spk_mu': spk_mu, 'spk_log_std': spk_log_std,\"z_spk\":z_spk,'emocls':emoresult,'spkcls':spkresult}\n","\n","\n","    def get_feature(self,z):\n","        h=self.shared(z)\n","        return h\n","\n","    def get_emo(self,x):\n","        h=self.shared(x)\n","        emo_mu, emo_log_std = self.emotionencoder(h)\n","        dec_in = torch.cat([emo_mu, emo_log_std], dim=1)\n","        emoresult=self.emocls(dec_in)\n","\n","    def get_spk(self,x):\n","        h=self.shared(x)\n","        spk_mu, spk_log_std = self.speakerencoder(h)\n","        dec_in = torch.cat([spk_mu, spk_log_std], dim=1)\n","        spkresult=self.spkcls(dec_in)\n","\n"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"TOWY-EK7I5dy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1738697644647,"user_tz":300,"elapsed":3,"user":{"displayName":"Chaohao Lin","userId":"02535404984035233613"}},"outputId":"b736bf12-49c0-46a6-ad87-b1cd4932b320"},"outputs":[{"output_type":"stream","name":"stdout","text":["L1 Squared Loss: 8.55704402923584\n"]}],"source":["import torch\n","import torch.nn as nn\n","\n","class L1SquaredLoss(nn.Module):\n","    def __init__(self, reduction='mean'):\n","        super(L1SquaredLoss, self).__init__()\n","        self.reduction = reduction\n","\n","    def forward(self, input, target):\n","        # Compute the absolute differences\n","        abs_diff = torch.abs(input - target)\n","        # Square the differences\n","        squared_diff = abs_diff ** 2\n","\n","        if self.reduction == 'mean':\n","            # Compute the mean of squared differences\n","            return torch.mean(squared_diff)\n","        elif self.reduction == 'sum':\n","            # Compute the sum of squared differences\n","            return torch.sum(squared_diff)\n","        else:\n","            # Return the squared differences as is\n","            return squared_diff\n","\n","# Example usage\n","input = torch.tensor([1.0, 2.0, 3.0], requires_grad=True)\n","target = torch.tensor([1.5, 2.5, 3.5])\n","\n","loss_1 = L1SquaredLoss(reduction='mean')\n","loss = loss_fn(input, target)\n","\n","print(\"L1 Squared Loss:\", loss.item())"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"NECekuINEU8B","executionInfo":{"status":"ok","timestamp":1738697646948,"user_tz":300,"elapsed":276,"user":{"displayName":"Chaohao Lin","userId":"02535404984035233613"}}},"outputs":[],"source":["def sample(mu, logs, std=1.):\n","    \"\"\"\n","    :param mu: [batch, channel]\n","    :param logs:[batch, channel]\n","    :param std: sampling std\n","    :return: sample: [batch, channel]\n","    \"\"\"\n","    assert std > 0.\n","    eps = torch.normal(torch.zeros_like(mu), torch.ones_like(logs) * std)\n","    sample = eps * torch.exp(logs) + mu\n","    return sample\n","\n","def kl_divergence(mu, log_std):\n","    \"\"\"\n","    :param mu: [B, C]\n","    :param log_std: [B, C]\n","    :return:\n","    \"\"\"\n","    post = D.Normal(mu, torch.exp(log_std))\n","    prior = D.Normal(\n","        torch.zeros_like(mu, requires_grad=False),\n","        torch.ones_like(log_std, requires_grad=False))\n","    kl = D.kl.kl_divergence(post, prior)\n","    kl = torch.mean(torch.sum(kl, dim=1))\n","    return kl\n","\n","def loss_cls(x,y):\n","    loss_3=nn.CrossEntropyLoss()\n","    # 1. Forward pass\n","    x=x.type(torch.float32)\n","    # 2. Calculate the loss\n","    loss = loss_3(x, y.long())\n","    return loss\n","\n","def loss_fn(self, outputs, x_gt, emo_gt,spk_gt):\n","    x_hat = outputs['x_hat']\n","    emo_mu = outputs['emo_mu']\n","    emo_log_std = outputs['emo_log_std']\n","    spk_mu = outputs['spk_mu']\n","    spk_log_std = outputs['spk_log_std']\n","\n","    emo_kl = kl_divergence(emo_mu, emo_log_std)\n","    spk_kl = kl_divergence(spk_mu, spk_log_std)\n","\n","    mi_loss=mutual_information(sample(emo_mu, emo_log_std),sample(spk_mu, spk_log_std))\n","    loss_2 = nn.MSELoss()\n","    nll = 0.5*loss_1(x_hat, x_gt) + 0.5*loss_2(x_hat, x_gt)\n","\n","    emo_cls=loss_cls(emoresult, emo_gt)\n","    spk_cls=loss_cls(spkresult,spk_gt)\n","    return nll, emo_kl, spk_kl,mi_loss,"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IxJWgp7YG6ro"},"outputs":[],"source":["\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cdmqj4MyHAP6"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K1sw_YWWJlUG"},"outputs":[],"source":["        if not self.validation: # random scale for robustness\n","            random_scale = 0.5 + 0.5 * np.random.random()\n","            wave_tensor = random_scale * wave_tensor"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":297,"status":"ok","timestamp":1738697650370,"user":{"displayName":"Chaohao Lin","userId":"02535404984035233613"},"user_tz":300},"id":"Se1oznWrMtTg","outputId":"cd46f67e-a66b-4e00-fc97-ffa58ce18163"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mutual Information: 0.35182283009427096\n"]}],"source":["import torch\n","import numpy as np\n","\n","def mutual_information(x, y, bins=30):\n","    # \n","    joint_hist = np.histogram2d(x.numpy(), y.numpy(), bins=bins)[0]\n","    # \n","    joint_prob = joint_hist / np.sum(joint_hist)\n","    # \n","    x_prob = np.sum(joint_prob, axis=1)\n","    y_prob = np.sum(joint_prob, axis=0)\n","\n","    # \n","    x_entropy = -np.sum(x_prob * np.log2(x_prob + 1e-9))\n","    y_entropy = -np.sum(y_prob * np.log2(y_prob + 1e-9))\n","    joint_entropy = -np.sum(joint_prob * np.log2(joint_prob + 1e-9))\n","\n","    # \n","    mi = x_entropy + y_entropy - joint_entropy\n","    return mi\n","\n","# \n","x = torch.randn(1000)\n","y = torch.randn(1000)\n","\n","# \n","mi = mutual_information(x, y)\n","print(f\"Mutual Information: {mi}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":196,"status":"ok","timestamp":1715893148872,"user":{"displayName":"Chaohao Lin","userId":"02535404984035233613"},"user_tz":240},"id":"qm-hMkE-M3ra","outputId":"03e21dab-caa6-4dd8-bcf8-37a5d5558080"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([ 1.2023e-01, -1.0938e-01,  9.2207e-01,  9.7151e-01, -9.9844e-01,\n","         1.8434e-02,  4.9694e-01,  8.8153e-01, -2.2785e-01, -5.4474e-01,\n","         1.3488e+00, -2.0486e+00,  1.4976e+00,  3.9248e-01, -3.7313e-01,\n","         1.1264e+00,  1.0988e+00,  4.9464e-01, -2.2593e-01, -1.8420e-01,\n","        -1.2816e+00, -1.4587e+00, -7.3192e-01, -1.2724e+00,  2.4385e+00,\n","        -2.1902e-01,  8.0240e-01,  2.5104e-01,  1.7762e-02,  3.7625e-02,\n","         1.9639e-02,  8.9844e-01,  1.3591e+00,  1.8403e+00,  3.1363e-01,\n","        -3.1421e-01,  2.3234e+00,  4.6285e-01,  8.4518e-01,  1.1116e-01,\n","        -1.0104e-01,  1.7546e+00,  5.3479e-01, -1.4233e+00, -3.7547e-01,\n","        -9.2472e-01, -2.7425e-01,  3.8717e-01,  6.5675e-01, -7.2609e-01,\n","         1.2645e+00, -7.1132e-01, -9.8459e-01,  5.5886e-01, -2.2345e-01,\n","        -8.1661e-02,  5.0329e-01,  3.4073e-01,  6.5831e-01, -9.2395e-01,\n","         1.0297e+00,  2.9020e-01,  2.9688e+00, -4.8891e-01, -7.4707e-01,\n","         1.1329e+00,  2.4070e-03, -1.5816e+00, -7.3338e-01,  8.8091e-01,\n","         9.1865e-01,  3.7227e-01, -5.4305e-01, -1.6084e-01, -2.3934e+00,\n","         7.8061e-02,  1.2200e-01,  7.8413e-02, -1.6963e+00,  2.9117e-02,\n","         9.0095e-01,  1.5509e-01, -2.0693e+00,  3.0424e-01, -1.8344e-01,\n","        -1.0717e+00, -5.5554e-01, -9.5264e-01, -5.4877e-01, -1.1338e+00,\n","         5.8088e-01,  9.2014e-01, -6.1527e-01, -5.5330e-01, -2.8669e-01,\n","         7.2442e-01,  8.5110e-01, -2.0377e+00,  2.3128e-01, -8.1357e-01,\n","         5.0936e-01,  1.2871e+00, -5.5190e-01,  6.9857e-01,  8.1194e-01,\n","         3.1500e-01,  1.2455e-01,  5.7831e-01, -1.2100e+00,  4.8970e-01,\n","         4.3975e-01,  1.5613e-01, -4.5610e-02,  1.1832e+00, -3.2987e+00,\n","        -1.6312e+00, -6.1034e-01, -3.1885e-01,  1.4312e+00,  3.4980e-01,\n","        -8.6423e-01, -8.1373e-01,  2.7109e-01,  1.6594e-01,  3.8244e-01,\n","        -2.7674e-01,  9.6236e-01, -1.4604e+00,  3.2108e-01,  7.9256e-01,\n","        -5.2906e-01,  6.0430e-01,  4.4648e-01,  1.4414e+00,  4.3849e-01,\n","        -1.9490e+00,  1.0727e+00, -9.0413e-01,  1.5060e-01, -7.1366e-01,\n","         3.6759e-01, -2.4214e-01, -2.4163e+00, -5.8317e-02, -7.7363e-01,\n","        -1.7768e+00, -3.1061e-01, -1.0720e+00, -1.2344e+00, -3.6686e-01,\n","         5.3540e-01, -1.2437e-01, -1.9176e-01, -1.2620e+00,  7.5841e-01,\n","        -1.5310e+00, -1.9594e-01,  1.1470e+00, -1.4541e-01,  2.1464e-01,\n","        -9.1798e-02,  4.3783e-01,  1.6415e+00,  1.2062e+00,  4.8355e-02,\n","        -1.2670e-01, -9.1735e-01, -7.2359e-01, -9.7379e-01, -9.4157e-01,\n","         9.4843e-01, -7.6086e-01,  6.9769e-01,  1.8075e-01, -1.6578e+00,\n","         5.1512e-01,  3.1562e-01,  1.1054e+00,  5.9164e-01, -1.4617e+00,\n","         5.8324e-03,  2.6239e-02, -9.6779e-01, -2.7717e-01,  2.7444e-01,\n","        -2.6999e-01,  6.1475e-01, -1.5336e-01,  3.2162e-01, -1.6810e-02,\n","        -5.2798e-01,  1.9074e-01,  1.3035e+00,  3.0599e-01,  5.4812e-01,\n","        -2.5594e-01, -8.6980e-01, -4.5385e-01, -9.6942e-01,  8.4115e-01,\n","         1.2484e+00,  8.5483e-01, -1.6817e+00, -1.6273e+00,  1.4655e-01,\n","        -9.8130e-01,  1.4878e+00, -1.1189e+00, -1.2265e+00,  8.9966e-01,\n","        -8.7588e-01,  1.8287e-01,  4.0413e-01, -8.4355e-01,  1.9934e+00,\n","         1.3442e+00,  7.9476e-01, -7.7900e-02, -2.0539e-02,  1.8313e+00,\n","         2.1130e+00,  5.1178e-01, -7.1847e-01,  3.0237e-01,  9.4592e-01,\n","        -5.7102e-01,  1.8214e+00,  3.3272e-01,  1.1122e+00, -4.7395e-01,\n","         2.7995e-01, -6.7621e-01,  1.2451e+00,  5.3815e-03, -1.2291e+00,\n","        -9.1197e-01,  6.6063e-01,  7.5015e-01, -2.1699e+00,  1.1769e+00,\n","         2.2824e-01, -1.0579e-01,  6.9669e-01, -3.2672e-01, -1.2535e-01,\n","        -1.2009e+00, -4.8969e-01, -5.1715e-01,  7.9636e-01, -8.2423e-01,\n","         3.1544e-01,  7.7137e-01,  7.9562e-01, -1.7788e+00, -9.6490e-01,\n","         9.4134e-01, -5.2593e-01,  1.1177e+00,  4.5811e-01, -6.5765e-01,\n","        -1.0979e+00, -1.4952e+00,  9.0152e-01,  7.9541e-01, -1.2031e+00,\n","        -3.6058e-01,  6.4980e-01,  3.9016e-02,  9.9583e-01,  1.0482e+00,\n","         1.4624e+00,  1.9933e-02,  4.6560e-01, -9.5413e-01, -3.6341e-01,\n","         2.4580e+00, -2.7615e-01, -3.8586e-01, -2.9702e-01,  1.4842e+00,\n","         9.5603e-01, -4.7527e-01, -1.2883e-01, -1.4671e-01,  3.4260e-02,\n","        -9.1256e-01,  1.4480e+00, -1.2171e-01,  8.7948e-01,  5.3951e-01,\n","        -2.9074e+00,  1.8026e+00, -7.5590e-01, -1.2006e+00, -1.5188e+00,\n","        -5.7115e-01, -4.1160e-01,  7.3913e-01,  4.4390e-01, -5.3814e-01,\n","        -8.2197e-01,  1.0157e+00,  1.4835e-01, -3.5019e-01,  3.1566e+00,\n","         2.0265e+00, -1.1581e+00, -4.4213e-01, -2.8282e-01,  4.2557e-01,\n","         7.0555e-01, -5.4232e-02,  7.1973e-01, -2.0367e+00,  6.3909e-01,\n","         7.5779e-01, -9.1306e-01,  4.8691e-01, -4.9990e-01, -5.3974e-01,\n","        -3.4121e-01, -5.0008e-01,  3.1726e-01, -1.8052e-02,  2.3753e+00,\n","         6.8832e-01, -7.2454e-01, -1.2463e+00,  2.1489e+00,  6.4788e-01,\n","         2.3251e+00, -2.8940e+00, -1.1175e+00,  9.3010e-02, -3.3405e-01,\n","         8.8505e-01, -1.5990e+00, -1.4602e-01, -1.2035e+00, -1.6333e+00,\n","         2.1520e+00, -2.9106e+00,  3.0814e+00,  7.1773e-02, -9.6866e-02,\n","        -8.4575e-01, -8.8927e-02, -3.7946e-01, -1.2425e+00,  8.7877e-02,\n","        -9.8901e-01,  1.6047e+00,  4.7127e-01, -4.8979e-01,  7.0109e-01,\n","        -1.2809e-01,  9.1226e-01,  7.9469e-01, -4.1398e-01, -1.3102e-01,\n","         7.9394e-01,  9.7318e-01,  7.3280e-01, -3.8371e-02,  2.3689e+00,\n","        -1.3256e+00, -9.4362e-01,  1.8668e+00,  9.0565e-01,  1.9997e+00,\n","         6.5432e-01,  1.6258e+00, -1.1918e+00, -1.8914e-01,  1.3267e+00,\n","        -7.2545e-01, -1.9036e-01,  8.9591e-01, -8.9566e-01, -4.3845e-01,\n","        -5.7449e-01, -1.4992e+00,  1.5237e-01,  6.9882e-01, -5.8866e-02,\n","         2.0244e+00,  8.7174e-01,  1.2675e+00,  1.7910e+00, -2.8500e-01,\n","        -1.1887e+00, -1.4617e+00,  1.5167e-01, -2.1628e+00, -8.2854e-01,\n","        -2.4353e-01,  3.3533e-01, -1.0276e+00, -4.6000e-01, -1.6080e+00,\n","        -5.2481e-02,  1.6733e+00,  5.3442e-01, -6.7872e-01, -2.2567e-01,\n","        -3.4101e-01,  3.2117e-01,  3.5638e-01, -2.0179e-01,  1.2716e-01,\n","         6.9139e-02,  7.1016e-01, -1.9129e+00, -1.0168e+00,  1.3045e+00,\n","         9.6141e-01,  4.0883e-01, -7.1282e-03,  1.5190e-01, -4.5326e-01,\n","        -7.3113e-01,  7.0530e-01,  1.1369e+00,  4.7930e-01,  4.9217e-01,\n","         1.0841e+00,  8.5641e-01,  4.8876e-01,  2.1377e-01,  8.7275e-01,\n","        -1.1143e+00, -1.2166e+00, -2.7009e-01,  3.9483e-01, -1.2360e+00,\n","         1.0685e-01, -2.5479e-01,  7.2265e-01, -4.4633e-01, -1.2628e-01,\n","         9.1346e-01, -1.0420e-01, -3.9022e-01,  2.4135e+00, -1.4471e+00,\n","         1.7188e+00, -1.3155e+00, -1.4008e+00, -3.9115e-01, -1.5468e+00,\n","         1.3281e+00,  8.8980e-01, -1.9396e-01,  4.8320e-01,  8.0226e-01,\n","        -5.8337e-01, -1.7984e+00, -1.5545e+00, -2.9741e-01,  1.2051e+00,\n","         6.6448e-02,  1.0856e+00,  1.3357e+00,  2.2802e-01,  5.6357e-01,\n","        -8.6818e-01,  3.6270e-01, -8.5632e-01,  4.1982e-01,  3.6485e-01,\n","        -8.2421e-01,  5.7991e-01, -2.2029e+00,  2.3042e+00,  4.6092e-01,\n","        -2.1916e-01,  1.6611e+00,  6.1478e-01,  3.8560e-02, -1.4165e+00,\n","         5.7959e-01, -3.5646e-01, -7.2249e-01, -2.0241e+00, -5.4831e-01,\n","        -1.7511e+00, -1.2452e-01, -7.8314e-01,  4.2317e-02,  1.4078e+00,\n","        -8.7820e-02, -3.0334e-01,  1.6330e+00, -1.8761e+00, -8.2935e-01,\n","        -4.9204e-01,  4.6574e-01,  5.0846e-01, -8.6808e-03,  1.6399e+00,\n","        -4.6358e-01, -5.1382e-01,  1.8365e-01, -8.7645e-01,  4.1020e-01,\n","        -5.1180e-02, -5.0441e-01, -1.3212e+00, -2.2297e-04, -1.0725e+00,\n","        -9.2085e-01,  4.6069e-01,  1.6165e+00, -4.5492e-01,  1.7960e-01,\n","         4.1564e-01, -2.8248e-01, -8.7660e-01, -1.8509e+00, -6.4683e-01,\n","         8.9116e-01,  5.7414e-01, -3.9254e-01, -1.1790e+00, -7.2277e-01,\n","        -7.2830e-01, -1.6868e+00, -1.2431e+00, -2.9665e-02, -9.9924e-01,\n","         1.2336e+00,  5.2220e-01,  1.0226e+00,  5.9640e-01,  5.9916e-01,\n","        -5.3087e-01,  7.4425e-02,  7.8034e-01, -1.1616e+00,  1.0539e+00,\n","        -9.5584e-01,  9.5499e-01,  2.5054e-01, -2.1821e-01,  7.8198e-01,\n","         2.0605e-02,  4.1867e-01,  1.6956e+00, -1.0608e+00,  1.8372e+00,\n","         1.5577e-01,  6.4842e-01,  5.8942e-01, -4.6973e-01, -1.0199e+00,\n","        -4.5845e-01,  2.1739e+00,  1.7977e+00, -2.0608e+00,  3.6504e-01,\n","         2.7452e-02, -7.9459e-01, -2.6459e-01,  3.3164e-01,  1.7313e-01,\n","        -3.7756e-01,  1.2746e+00,  5.1792e-01,  1.0105e-01, -5.0507e-01,\n","         1.0602e+00, -7.7913e-01, -5.4989e-01, -1.4855e-01,  3.0999e-01,\n","        -9.0241e-02, -3.5641e-01, -1.5995e+00, -8.3273e-01,  2.0483e+00,\n","         3.5869e-01,  5.6361e-01,  1.5520e+00, -4.7566e-01,  1.4329e+00,\n","         1.9849e+00,  4.4550e-02,  1.0390e+00, -1.4272e+00,  9.3841e-01,\n","         7.3052e-01, -2.8085e-01,  1.7672e+00, -3.5277e-01, -1.7258e+00,\n","         5.3691e-01, -1.5148e+00, -5.0420e-01, -6.5379e-01,  6.0675e-01,\n","         2.2835e-01, -9.0165e-01,  3.9661e-01,  2.7966e+00,  2.7312e-01,\n","         6.3531e-01,  1.1493e+00, -5.4661e-01, -2.1373e-01, -7.3445e-02,\n","        -3.9581e-02,  1.4476e-01, -1.5895e+00, -1.2488e+00, -1.2695e+00,\n","         6.7781e-01, -8.2115e-01,  1.0189e-02,  3.3232e-01,  4.1871e-01,\n","         5.4840e-01,  1.7748e+00,  1.6288e-03, -1.1938e+00,  1.4696e+00,\n","        -1.0750e-01,  3.2049e-01, -3.5593e-01, -1.1248e+00, -9.3265e-01,\n","        -8.9624e-01,  6.4961e-01, -1.3675e+00, -3.3627e-01,  2.2072e-01,\n","        -1.2730e+00,  8.9061e-01, -3.0546e-01,  3.3828e-01, -3.8169e-01,\n","         4.2699e-01, -1.0604e+00, -1.7541e-01,  1.0190e+00,  1.0342e+00,\n","        -1.0618e+00, -2.7700e-01,  1.5363e+00,  1.5950e+00,  1.2721e+00,\n","        -4.6089e-01,  1.6059e-02,  1.6696e+00,  9.8951e-01,  3.2750e-01,\n","        -6.4066e-01, -7.9538e-01, -1.2561e+00,  4.0811e-01, -8.3237e-02,\n","         6.0378e-01, -1.2523e+00, -8.1652e-01, -2.2387e-01,  3.2678e-01,\n","         1.7203e+00,  9.7278e-01, -4.6515e-01, -1.8605e-01,  9.5089e-01,\n","        -1.0581e+00,  4.1672e-01,  6.0371e-01,  9.1567e-01,  5.1203e-01,\n","        -1.6607e-01,  5.2575e-01, -5.6177e-01,  4.0609e-01,  1.2847e-01,\n","         1.3266e+00, -1.4243e+00, -8.2883e-01,  7.6093e-01,  1.1477e+00,\n","        -2.1652e-01, -4.4064e-01, -7.0841e-01,  8.0930e-01, -3.5615e-01,\n","        -4.5372e-01, -1.1554e+00, -6.0887e-01,  2.6204e-01, -5.5960e-01,\n","        -6.1519e-01, -1.5257e+00, -4.6798e-01, -1.7163e+00,  5.0818e-01,\n","        -6.2893e-01, -1.0687e+00, -1.8969e-01,  2.7780e-01, -1.5157e+00,\n","        -6.9273e-01, -1.2319e+00,  1.5855e+00,  1.5620e+00,  1.1452e+00,\n","         1.4299e+00, -1.3477e+00, -2.0965e-01,  1.3380e+00,  2.1291e-01,\n","         6.0172e-01,  8.9463e-01, -4.9492e-01, -7.3104e-01,  7.9730e-01,\n","        -9.3288e-01, -1.2943e+00,  4.4969e-01, -1.1968e+00,  4.8622e-01,\n","         1.9684e+00, -6.7169e-02,  1.6086e+00,  1.5082e+00, -1.4394e+00,\n","         1.1881e+00,  1.3325e+00,  1.1809e+00,  5.1086e-01, -2.1321e+00,\n","         2.0387e-01,  8.1601e-01,  3.4304e-01, -1.4499e+00,  1.4737e+00,\n","        -6.6609e-01,  1.8232e-02, -1.2240e-01, -9.6978e-01, -5.9450e-01,\n","        -1.0379e-01, -2.7756e-01,  1.1285e-01, -3.0995e-01, -1.0061e+00,\n","         2.1136e+00, -2.2974e-01, -1.6878e+00, -5.6815e-01, -1.1888e-01,\n","        -9.8575e-01,  1.2624e+00,  5.9972e-01, -3.0043e+00,  2.2011e+00,\n","         8.7000e-01, -1.1866e+00, -5.5701e-01, -6.2889e-01, -1.2954e+00,\n","        -1.1693e+00, -5.4311e-01,  3.3000e-01, -3.3413e-01,  6.3776e-01,\n","        -1.6174e+00, -5.4383e-01,  6.9777e-01, -2.1664e+00,  5.1387e-01,\n","         2.3580e+00, -2.8364e-01,  1.3415e+00,  1.9962e-01, -1.0347e-01,\n","        -7.3386e-01, -1.4405e-01, -1.0669e-01, -1.9476e+00,  1.3307e+00,\n","         7.4802e-01,  2.2385e-02, -5.2835e-01, -3.9275e-01, -1.1705e+00,\n","        -4.4711e-01, -4.3806e-01, -6.8702e-01,  3.2612e-01, -1.2636e+00,\n","        -1.2361e+00,  4.3264e-01, -1.1735e+00, -2.0835e-02, -7.2853e-01,\n","         2.3382e-01, -6.4257e-01,  5.8054e-03,  1.3219e+00, -8.1134e-01,\n","         1.1960e+00, -1.8637e+00,  1.2487e+00,  6.8500e-01,  5.2038e-01,\n","        -6.4151e-01,  3.0446e-02, -8.0747e-02, -5.0596e-01, -9.7163e-01,\n","        -1.6844e-01,  1.7137e+00, -1.1627e+00,  5.2382e-01, -1.7161e-02,\n","        -1.2898e+00,  1.1749e-01,  2.2283e-01, -6.1596e-01, -1.6390e+00,\n","        -3.1574e-01,  6.1110e-01, -6.9327e-01, -2.8515e-01, -9.0036e-01,\n","        -9.1343e-01, -2.1243e-01,  8.7182e-01,  2.1583e-01, -9.5932e-01,\n","        -1.8914e-02, -7.7709e-01,  1.0474e-03,  5.0597e-02, -8.1136e-01,\n","         1.5321e+00,  1.4824e+00, -5.8834e-01,  7.3774e-01,  6.8278e-01,\n","         1.3161e+00,  7.5450e-01,  5.3875e-01, -7.2564e-01,  2.9835e-01,\n","        -6.3805e-01,  9.9876e-01,  1.7011e+00, -1.6256e+00,  7.6382e-01,\n","         1.2027e+00, -3.4100e-02,  1.2539e-01, -1.1275e+00, -2.9151e-01,\n","        -7.3530e-01, -1.3599e-01, -3.7139e-01,  1.6366e+00, -2.0443e-01,\n","         7.7921e-01,  3.6938e-02,  5.0740e-01,  1.3111e+00, -2.0653e+00,\n","         9.4882e-01,  6.5352e-01, -1.8223e-01, -2.1640e-01, -7.6040e-01,\n","        -5.8930e-01, -2.6791e-01,  3.1754e-01,  9.8705e-02,  2.0096e+00,\n","        -1.1175e+00, -1.6891e+00, -1.3154e+00,  5.5111e-01, -4.0524e-01,\n","         1.0364e+00, -1.3456e+00,  8.1319e-01,  4.4267e-01,  9.4771e-01,\n","        -6.0764e-01,  1.2814e+00,  1.0038e+00,  1.2189e+00,  4.2331e-01,\n","        -7.6815e-01,  3.4359e-01,  7.0991e-01,  1.6249e-01,  7.9921e-01,\n","        -1.6481e-01,  6.7747e-01,  1.4094e+00, -1.6151e-02, -1.5111e+00,\n","         4.2384e-01,  2.8294e-01,  9.3988e-02,  5.8895e-01, -2.4440e-01,\n","         1.1216e+00,  1.9964e-01,  2.6429e-01, -5.2777e-01, -1.6519e-01,\n","         2.0249e-01, -2.1928e+00, -1.4390e-01,  4.1245e-01,  1.3911e+00,\n","         1.0084e+00, -6.4507e-01, -6.3798e-01,  4.3769e-01, -2.6081e+00,\n","         8.5880e-01, -3.1372e-01,  1.9590e+00, -4.8072e-01,  1.1573e+00,\n","        -8.2973e-01,  4.3628e-02, -1.0490e+00,  9.6089e-01, -1.2091e+00,\n","        -1.4249e-02, -2.4369e+00,  2.0627e+00, -1.1941e+00, -3.3985e-01,\n","        -4.6753e-01, -1.3334e+00,  1.6003e-01,  5.6343e-01, -1.2293e+00,\n","         1.2020e+00,  4.4205e-01,  8.2767e-01, -1.0021e+00,  4.4617e-01,\n","         1.1554e+00, -1.6738e+00, -1.3859e-01, -1.0290e+00,  9.5827e-01,\n","        -3.7706e-02,  2.1415e+00, -4.9514e-01, -8.1964e-01, -2.0341e-01,\n","         1.0924e+00,  1.1646e-01, -2.5039e-01, -1.9151e+00,  2.5352e-01,\n","         4.1464e-01,  2.7678e-01, -1.4761e+00,  1.8277e+00,  6.9311e-02,\n","        -2.8706e-01, -4.7836e-01,  2.8406e-01, -1.0786e+00, -1.5242e+00,\n","         8.0853e-01, -2.5682e-01,  2.1404e+00,  7.2980e-01, -5.1602e-01,\n","         9.9431e-01, -7.4646e-01,  4.2432e-01,  5.7043e-02, -1.5626e+00,\n","        -8.4142e-02, -6.2155e-02, -7.0355e-01,  1.2283e+00, -5.6538e-01,\n","        -8.5586e-01,  1.3577e-01,  9.8252e-01,  1.3449e-01,  3.8364e-01,\n","        -4.6914e-01, -1.2816e+00,  3.3888e-01, -4.3518e-01,  5.0446e-01])\n"]}],"source":["print(y)"]}],"metadata":{"colab":{"provenance":[],"machine_shape":"hm","authorship_tag":"ABX9TyOR43WiEUvT/ZbZE1Num9EA"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"f6e54051c5e7456fae85a41652a61ff5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_42d8d50db21747808f0514b28c40bb3b","IPY_MODEL_22b7ec64d2ac4975aac0a0d0edac2281","IPY_MODEL_567a33e934af4a2ca97082904dfce9b6"],"layout":"IPY_MODEL_fa89217af99a4791881046dba732b95a"}},"42d8d50db21747808f0514b28c40bb3b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8a29f836f7814933a344b3b3c85ce9c9","placeholder":"","style":"IPY_MODEL_c98ce58529e5430e92d6c2cfa6a1946d","value":"3%"}},"22b7ec64d2ac4975aac0a0d0edac2281":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_ab6096108d9e45b7a1ff3531e5ee2b65","max":400,"min":0,"orientation":"horizontal","style":"IPY_MODEL_28417682f3d8421596229acbd39c73f6","value":11}},"567a33e934af4a2ca97082904dfce9b6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e110b623844e44a6beab52785b173877","placeholder":"","style":"IPY_MODEL_ea52840e5f124eeb9d38b1dc7f94e94b","value":"11/400[00:14&lt;08:08,1.26s/it]"}},"fa89217af99a4791881046dba732b95a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8a29f836f7814933a344b3b3c85ce9c9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c98ce58529e5430e92d6c2cfa6a1946d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ab6096108d9e45b7a1ff3531e5ee2b65":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"28417682f3d8421596229acbd39c73f6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e110b623844e44a6beab52785b173877":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ea52840e5f124eeb9d38b1dc7f94e94b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}